{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "\n",
    "* PEFT technique: LoRA\n",
    "* Model: GPT-2\n",
    "* Evaluation approach: Transformer Trainer\n",
    "* Fine-tuning dataset: Rotten Tomatoes (https://huggingface.co/datasets/rotten_tomatoes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Install dataset module to be able to run HugginfFace dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f551c63a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.23.0\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.7/450.7 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: packaging in /home/student/.local/lib/python3.10/site-packages (from datasets) (24.0)\n",
      "Collecting tqdm>=4.66.3\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /home/student/.local/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: pandas in /home/student/.local/lib/python3.10/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/student/.local/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in /home/student/.local/lib/python3.10/site-packages (from datasets) (2024.2.0)\n",
      "Requirement already satisfied: filelock in /home/student/.local/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Collecting requests>=2.32.2\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/student/.local/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/student/.local/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets) (4.10.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/student/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/student/.local/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/student/.local/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/student/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: tqdm, requests, huggingface-hub, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.2\n",
      "    Uninstalling tqdm-4.66.2:\n",
      "      Successfully uninstalled tqdm-4.66.2\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/home/student/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.21.4\n",
      "    Uninstalling huggingface-hub-0.21.4:\n",
      "      Successfully uninstalled huggingface-hub-0.21.4\n",
      "\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/student/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script datasets-cli is installed in '/home/student/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed datasets-3.2.0 huggingface-hub-0.27.1 requests-2.32.3 tqdm-4.67.1\n",
      "\u001b[33m  WARNING: The script datasets-cli is installed in '/home/student/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets\n",
    "\n",
    "!pip install -q \"datasets==2.15.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c386866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.2)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a079df",
   "metadata": {},
   "source": [
    "##  Import  Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "946de8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "import numpy as np\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from peft import LoraConfig, PeftModelForSequenceClassification, TaskType, AutoPeftModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f1d1b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred   \n",
    "    predictions = np.argmax(predictions, axis=1)    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    return {\"accuracy\": accuracy_score(labels, predictions), \"f1\": f1, \"precision\": precision, \"recall\": recall}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38645065",
   "metadata": {},
   "source": [
    "## Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4935cb4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b239e1c61c2d46c5abd9b8020b251ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926248c94c154d75b5107cd68330de56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891aee9a73d042d69f390df82e1f5e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/699k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af73265e5144e4eb8748a626066b7b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/90.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329bd698ff564a4c90d928de0ac68ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/92.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8354812fca84d079273961c9883e5d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b6d4ed7ce04ef9b3d19f81bbc7243c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f001d38cf164945b0f7807f9724e7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9f8ceefa1c42208713ba4416b89240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"rotten_tomatoes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a178d26",
   "metadata": {},
   "source": [
    "## Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a86621c64b4a76acd3c40aaf253ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdbc6c43ae07452088e36e7b95bca369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205a9a77bb71482d916e5445897efcfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695a1096fda340b58b7ae4c3e2fd1697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df02551d1674219b9cd9bc7344e49ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ffbf75fa2748f7bdf7073921ea9812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c06cbef7a9494b83ac15c002f716d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269215ef565446b5a90af8ce3a8e8f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a691de580e42ccbe6ef139f3cbdbd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2ed924e48a4d198b99825bc6ae7777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7329cca2e80445fa97b580bd0a4f8010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80caef91bdb34727a885bbe23c2a6394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/733k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1863feb4cc6143ccaa7b70d5db799fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8aea4283c2c42cba0ce236726e2483f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/657k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d720752b8744692b94c5b134b55d088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15da20d108b14eb3aecc746bb479aaff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0b984026fb4c59a39b87fc2906fc4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270c839452bd44f7be34af78c41dba0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 8530\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the data to tokens so the model can understand\n",
    "# Load the base model and tokenizer\n",
    "base_model_name = \"gpt2\"  # Replace with your desired model\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    base_model_name,\n",
    "    num_labels=2,\n",
    "    id2label={0: \"Negative review\", 1: \"Positive review\"},\n",
    "    label2id={\"Negative review\": 0, \"Positive review\": 1},\n",
    ")\n",
    "\n",
    "\n",
    "# Adjust padding token if not defined\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "     \n",
    "tokenized_dataset = {}\n",
    "\n",
    "# Tokenize the datasets\n",
    "splits = [\"train\", \"test\", \"validation\"]\n",
    "for split in splits:\n",
    "    tokenized_dataset[split] = ds[split].map(\n",
    "        lambda x: tokenizer(x[\"text\"], truncation=True), batched=True)\n",
    "\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"train\")\n",
    "\n",
    "\n",
    "  \n",
    "# Inspect the available columns in the dataset\n",
    "tokenized_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "019b9f55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 147,456 || all params: 124,590,336 || trainable%: 0.11835267865398486\n"
     ]
    }
   ],
   "source": [
    "# Creates the outputs to be used as classification\n",
    "# PEFT model configuration\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=4,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "\n",
    "# Load the pre-trained GPT-2 model\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "peft_model = PeftModelForSequenceClassification(model, peft_config)\n",
    "\n",
    "# Print\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5a6d34",
   "metadata": {},
   "source": [
    "# Evaluate Foundation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5176b07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.875333547592163,\n",
       " 'eval_accuracy': 0.5,\n",
       " 'eval_f1': 0.3333333333333333,\n",
       " 'eval_precision': 0.25,\n",
       " 'eval_recall': 0.5,\n",
       " 'eval_runtime': 3.7163,\n",
       " 'eval_samples_per_second': 286.846,\n",
       " 'eval_steps_per_second': 4.574}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        # Set the learning rate\n",
    "        learning_rate = 2e-5,\n",
    "        # Set the per device train batch size and eval batch size\n",
    "        per_device_train_batch_size = 32,\n",
    "        per_device_eval_batch_size = 64,\n",
    "        # Evaluate and save the model after each epoch\n",
    "        evaluation_strategy = \"epoch\", \n",
    "        save_strategy = \"epoch\",\n",
    "        logging_dir=\"./logs\",\n",
    "        num_train_epochs=4,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        logging_steps=100,\n",
    "        warmup_ratio=0.1,\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9951990f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af320535",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "Create a PEFT model from loaded model, \n",
    "run a training loop, \n",
    "and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5775fadf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1068' max='1068' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1068/1068 04:26, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.494700</td>\n",
       "      <td>0.982745</td>\n",
       "      <td>0.498124</td>\n",
       "      <td>0.332498</td>\n",
       "      <td>0.249530</td>\n",
       "      <td>0.498124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.756700</td>\n",
       "      <td>0.686286</td>\n",
       "      <td>0.593809</td>\n",
       "      <td>0.593780</td>\n",
       "      <td>0.593835</td>\n",
       "      <td>0.593809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.712100</td>\n",
       "      <td>0.670212</td>\n",
       "      <td>0.604128</td>\n",
       "      <td>0.604059</td>\n",
       "      <td>0.604199</td>\n",
       "      <td>0.604128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.706100</td>\n",
       "      <td>0.665112</td>\n",
       "      <td>0.612570</td>\n",
       "      <td>0.612554</td>\n",
       "      <td>0.612590</td>\n",
       "      <td>0.612570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()\n",
    "#save the PEFT model to be referenced later\n",
    "peft_model.save_pretrained('model/peft_model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f9f335",
   "metadata": {},
   "source": [
    "## Evaluate model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4d4c908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the saved PEFT model\n",
    "inference_model = AutoPeftModelForSequenceClassification.from_pretrained(\n",
    "    \"model/peft_model\",\n",
    "    num_labels=2\n",
    ")\n",
    "inference_model.config.pad_token_id = inference_model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b47abf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='17' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17/17 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.6313661932945251, 'eval_accuracy': 0.6951219512195121, 'eval_f1': 0.6943081941639292, 'eval_precision': 0.697221985028321, 'eval_recall': 0.6951219512195121, 'eval_runtime': 3.9093, 'eval_samples_per_second': 272.685, 'eval_steps_per_second': 4.349}\n"
     ]
    }
   ],
   "source": [
    "# Run the predictions using the test dataset\n",
    "trainer = Trainer(\n",
    "    model=inference_model,\n",
    "    args=training_args,\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_results_lora = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", evaluation_results_lora)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7fe003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db82f75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "978c4a90",
   "metadata": {},
   "source": [
    "## Tune paramters for PEFT Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "863ec66e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4272' max='4272' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4272/4272 08:31, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.714700</td>\n",
       "      <td>1.612783</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.773700</td>\n",
       "      <td>0.707834</td>\n",
       "      <td>0.560038</td>\n",
       "      <td>0.528179</td>\n",
       "      <td>0.582253</td>\n",
       "      <td>0.560038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.713100</td>\n",
       "      <td>0.673059</td>\n",
       "      <td>0.606942</td>\n",
       "      <td>0.606240</td>\n",
       "      <td>0.607710</td>\n",
       "      <td>0.606942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.696300</td>\n",
       "      <td>0.653602</td>\n",
       "      <td>0.638837</td>\n",
       "      <td>0.637135</td>\n",
       "      <td>0.641491</td>\n",
       "      <td>0.638837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.643300</td>\n",
       "      <td>0.636965</td>\n",
       "      <td>0.663227</td>\n",
       "      <td>0.663096</td>\n",
       "      <td>0.663481</td>\n",
       "      <td>0.663227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.700300</td>\n",
       "      <td>0.624456</td>\n",
       "      <td>0.669794</td>\n",
       "      <td>0.669417</td>\n",
       "      <td>0.670572</td>\n",
       "      <td>0.669794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.669100</td>\n",
       "      <td>0.616228</td>\n",
       "      <td>0.680113</td>\n",
       "      <td>0.679988</td>\n",
       "      <td>0.680393</td>\n",
       "      <td>0.680113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.667300</td>\n",
       "      <td>0.613611</td>\n",
       "      <td>0.681051</td>\n",
       "      <td>0.680938</td>\n",
       "      <td>0.681306</td>\n",
       "      <td>0.681051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "Checkpoint destination directory ./results/checkpoint-534 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory ./results/checkpoint-1068 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "peft_model2 = PeftModelForSequenceClassification(model, peft_config)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=1e-5,  # Smaller learning rate for stability\n",
    "    per_device_train_batch_size=16,  # Reduce batch size to fit in memory\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    num_train_epochs=8,  # Increase epochs for deeper fine-tuning\n",
    "    weight_decay=0.05,  # Stronger regularization\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=50,  # Log more frequently\n",
    "    warmup_ratio=0.2,  # Increased warmup ratio\n",
    "    save_total_limit=2,  # Limit saved checkpoints\n",
    "    metric_for_best_model=\"eval_f1\",  # Focus on F1 for binary classification\n",
    "    greater_is_better=True,  # F1 score should increase\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model2,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "peft_model2.save_pretrained('model/peft_model2')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc3a8147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:475: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "inference_model2 = AutoPeftModelForSequenceClassification.from_pretrained(\n",
    "    \"model/peft_model2\",\n",
    "    num_labels=2\n",
    ")\n",
    "inference_model2.config.pad_token_id = inference_model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc96905a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.6245055198669434, 'eval_accuracy': 0.6651031894934334, 'eval_f1': 0.6650793161866626, 'eval_precision': 0.6651502774569731, 'eval_recall': 0.6651031894934334, 'eval_runtime': 3.6257, 'eval_samples_per_second': 294.016, 'eval_steps_per_second': 9.378}\n"
     ]
    }
   ],
   "source": [
    "# Run the predictions using the test dataset\n",
    "trainer2 = Trainer(\n",
    "    model=inference_model2,\n",
    "    args=training_args,\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_results_lora2 = trainer2.evaluate()\n",
    "print(\"Evaluation Results:\", evaluation_results_lora2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use another LoRa configurations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9a32e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 124,737,792 || trainable%: 0.2364255413467636\n"
     ]
    }
   ],
   "source": [
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,  # Specify the task type\n",
    "    inference_mode=False,          # Ensure it's in training mode\n",
    "    r=8,                           # LoRA rank\n",
    "    lora_alpha=32,                 # Scaling factor\n",
    "    lora_dropout=0.1,              # Dropout for regularization\n",
    ")\n",
    "\n",
    "# Wrap the base model with PEFT\n",
    "peft_model3 = PeftModelForSequenceClassification(model, peft_config)\n",
    "\n",
    "# Print\n",
    "peft_model3.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "639f58d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4272' max='4272' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4272/4272 08:31, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.714900</td>\n",
       "      <td>1.611754</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.887400</td>\n",
       "      <td>0.793075</td>\n",
       "      <td>0.502814</td>\n",
       "      <td>0.355234</td>\n",
       "      <td>0.533328</td>\n",
       "      <td>0.502814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.736700</td>\n",
       "      <td>0.694322</td>\n",
       "      <td>0.593809</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.594608</td>\n",
       "      <td>0.593809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.716800</td>\n",
       "      <td>0.681839</td>\n",
       "      <td>0.594747</td>\n",
       "      <td>0.594741</td>\n",
       "      <td>0.594752</td>\n",
       "      <td>0.594747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.674300</td>\n",
       "      <td>0.673296</td>\n",
       "      <td>0.602251</td>\n",
       "      <td>0.602111</td>\n",
       "      <td>0.602396</td>\n",
       "      <td>0.602251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.733700</td>\n",
       "      <td>0.666715</td>\n",
       "      <td>0.607880</td>\n",
       "      <td>0.607830</td>\n",
       "      <td>0.607935</td>\n",
       "      <td>0.607880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.696800</td>\n",
       "      <td>0.662226</td>\n",
       "      <td>0.616323</td>\n",
       "      <td>0.616247</td>\n",
       "      <td>0.616415</td>\n",
       "      <td>0.616323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.715300</td>\n",
       "      <td>0.660829</td>\n",
       "      <td>0.618199</td>\n",
       "      <td>0.618142</td>\n",
       "      <td>0.618269</td>\n",
       "      <td>0.618199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=5e-6,  # Even smaller learning rate for fine adjustments\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    num_train_epochs=8,  # Slightly increase epochs\n",
    "    weight_decay=0.03,  # Slightly reduced weight decay\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=50,\n",
    "    warmup_ratio=0.15,  # Adjust warmup for balance\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model=\"eval_f1\",\n",
    "    greater_is_better=True,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=peft_model3,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "peft_model3.save_pretrained('model/peft_model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04702d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [34/34 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.6719444990158081, 'eval_accuracy': 0.6022514071294559, 'eval_f1': 0.6022458067127797, 'eval_precision': 0.6022571662917631, 'eval_recall': 0.6022514071294559, 'eval_runtime': 3.5796, 'eval_samples_per_second': 297.797, 'eval_steps_per_second': 9.498}\n"
     ]
    }
   ],
   "source": [
    "inference_model3 = AutoPeftModelForSequenceClassification.from_pretrained(\n",
    "    \"model/peft_model3\",\n",
    "    num_labels=2\n",
    ")\n",
    "inference_model3.config.pad_token_id = inference_model3.config.eos_token_id\n",
    "# Run the predictions using the test dataset\n",
    "trainer3 = Trainer(\n",
    "    model=inference_model3,\n",
    "    args=training_args,\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_results_lora3 = trainer3.evaluate()\n",
    "print(\"Evaluation Results:\", evaluation_results_lora3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb028cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
